#!/usr/bin/env bash
echo "
run a job interactively as follows:
srun --nodes=1 --ntasks-per-node=8 --time=01:00:00 --pty bash -i
"

if [ "$#" -eq 1 ] ; then
  f=$1
elif [ "$#" -gt 1 ] ; then
  echo "Using only first argument $1"
  f=$1
else
  f=$PWD/job.batch
fi 

if [ -f $f ] ; then 
  while true; do
     echo " Replace $f (y/N):"
     read answer
     ans="$(echo $answer | head -c 1)" 
     if [[ "$ans" == "y" ]] || [[ "$ans" == "Y" ]] ; then
        rm $f
        break
     elif [[ "$ans" == "n" ]] || [[ "$ans" == "N" ]] || [[ "$ans" == "" ]] ; then
        echo " aborting..."
        exit 0
     else
        echo " Invalid anser: $answer"
     fi 
  done 
fi

echo "#!/usr/bin/env bash
#
# run a job interactively as follows:
# srun --nodes=1 --ntasks-per-node=8 --time=01:00:00 --pty bash -i
#
#SBATCH --job-name=job
#SBATCH --output=slurm_%j.log
#SBATCH --error=slurm_%j.log
 
#SBATCH -N 1
#SBATCH --ntasks=22
#SBATCH --time=01:00:00

# print hosts 
# srun hostname 

# load modules 
#module load vasp-gnu_mkl-dev 
#module load vasp-nvidia_mkl-dev 
#module load vasp-intel_mkl-dev 

# parallel build 
#make -j\$SLURM_NTASKS std gam ncl DEPS=\$SLURM_NTASKS

# use this in combination with Intel MPI to enable "srun" 
#export I_MPI_PMI_LIBRARY=\$SLURM_PMI_LIB

# run job on multi nodes
#srun -N \$SLURM_NODES -n \$SLURM_NTASKS /path/to/exe

# run job with mpirun 
# mpirun -np \$SLURM_NTASKS /path/to/exe
" > $f

chmod +x $f
exit 0 
